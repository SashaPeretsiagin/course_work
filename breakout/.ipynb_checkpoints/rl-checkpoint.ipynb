{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RjXeuJpeITVu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jxfg0xeFIc9L"
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDpRVW53Su39"
   },
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYa5gDPZgMx4"
   },
   "outputs": [],
   "source": [
    "_IMAGE_FIRST_RANGE = 31\n",
    "_IMAGE_SECOND_RANGE = 195\n",
    "_MONITOR = True\n",
    "\n",
    "_EPOCHS = 100\n",
    "_THRESHOLD = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCH6u7i7gwmV"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOVr5442y-10"
   },
   "outputs": [],
   "source": [
    "\"\"\"Trains a DQN/DDQN to solve CartPole-v0 problem\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import gym\n",
    "from gym import wrappers, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9S3i4tpofk4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUb6b97TOf10"
   },
   "outputs": [],
   "source": [
    "_IMAGE_FIRST_RANGE = 31\n",
    "_IMAGE_SECOND_RANGE = 195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q4evYJXkoSXp",
    "outputId": "34ac06e7-8a5d-4abd-8807-ccf8230148f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-18 00:37:14,668] Making new env: Breakout-v0\n",
      "/Users/sashaperetsiagin/anaconda3/envs/tensorflow_vision/lib/python3.7/site-packages/gym/envs/registration.py:17: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"Breakout-v0\")\n",
    "obs = env.reset()\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NC6PLJdUPHpA"
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "  def __init__(self, state_space, action_space, batch_size=64, IM_SIZE = 84, m = 4):\n",
    "    self.action_space = action_space\n",
    "    self.memory = []\n",
    "    self.gamma = 0.9\n",
    "    self.epsilon = 1.0\n",
    "    self.epsilon_min = 0.1\n",
    "    self.epsilon_decay = 0.995\n",
    "    self.weights_file = 'pacman.h5'\n",
    "\n",
    "    self.IM_SIZE = IM_SIZE\n",
    "    self.m = m\n",
    "\n",
    "    n_inputs = state_space.shape[0]\n",
    "    n_outputs = action_space.n\n",
    "    self.q_model = self.build_model(n_inputs, n_outputs)\n",
    "    self.q_model.compile(loss='mse', optimizer=Adam())\n",
    "    self.target_q_model = self.build_model(n_inputs, n_outputs)\n",
    "    self.update_weights()\n",
    "    self.replay_counter = 0\n",
    "\n",
    "\n",
    "  def update_weights(self):\n",
    "    \"\"\"copy trained Q Network params to target Q Network\"\"\"\n",
    "    self.target_q_model.set_weights(self.q_model.get_weights())\n",
    "\n",
    "\n",
    "  def save_weights(self):\n",
    "    \"\"\"save Q Network params to a file\"\"\"\n",
    "    self.q_model.save_weights(self.weights_file)\n",
    "\n",
    "\n",
    "  def act(self, state):\n",
    "    if np.random.rand() < self.epsilon:\n",
    "      # explore - do random action\n",
    "      return self.action_space.sample()\n",
    "      # exploit\n",
    "    q_values = self.q_model.predict(state)\n",
    "      # select the action with max Q-value\n",
    "    action = np.argmax(q_values[0])\n",
    "    return action   \n",
    "\n",
    "\n",
    "  def remember(self, state, action, reward, next_state, done):\n",
    "    item = (state, action, reward, next_state, done)\n",
    "    self.memory.append(item)\n",
    "\n",
    "\n",
    "  def get_target_q_value(self, next_state, reward):\n",
    "    q_value = np.amax(self.target_q_model.predict(next_state)[0])\n",
    "    q_value *= self.gamma\n",
    "    q_value += reward\n",
    "    return q_value\n",
    "\n",
    "\n",
    "  def replay(self, batch_size):\n",
    "    sars_batch = random.sample(self.memory, batch_size)\n",
    "    state_batch, q_values_batch = [], []\n",
    "    for state, action, reward, next_state, done in sars_batch:\n",
    "      q_values = self.q_model.predict(state)\n",
    "      q_value = self.get_target_q_value(next_state, reward)\n",
    "      q_values[0][action] = reward if done else q_value\n",
    "      state_batch.append(state[0])\n",
    "      q_values_batch.append(q_values[0])\n",
    "\n",
    "    self.q_model.fit(np.array(state_batch), np.array(q_values_batch), batch_size=batch_size, epochs=1, verbose=0)\n",
    "\n",
    "    # update exploration-exploitation probability\n",
    "    self.update_epsilon()\n",
    "\n",
    "    # copy new params on old target after \n",
    "    # every 10 training updates\n",
    "    if self.replay_counter % 10 == 0:\n",
    "      self.update_weights()\n",
    "\n",
    "    self.replay_counter += 1\n",
    "\n",
    "\n",
    "  def preprocess_state(self, img):\n",
    "    img_temp = img[31:195]  # Choose the important area of the image\n",
    "    img_temp = tf.image.rgb_to_grayscale(img_temp)\n",
    "    img_temp = tf.image.resize(img_temp, [self.IM_SIZE, self.IM_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    img_temp = tf.cast(img_temp, tf.float32)\n",
    "    return img_temp[:,:,0]\n",
    "\n",
    "  \n",
    "  def combine_images(self, img1, img2):\n",
    "    if len(img1.shape) == 3 and img1.shape[0] == self.m:\n",
    "      im = np.append(img1[1:,:, :],np.expand_dims(img2,0), axis=2)\n",
    "      return tf.expand_dims(im, 0)\n",
    "    else:\n",
    "      im = np.stack([img1]*self.m, axis = 2)\n",
    "      return tf.expand_dims(im, 0)\n",
    "\n",
    "\n",
    "  def update_epsilon(self):\n",
    "    \"\"\"decrease the exploration, increase exploitation\"\"\"\n",
    "    if self.epsilon > self.epsilon_min:\n",
    "      self.epsilon *= self.epsilon_decay \n",
    "\n",
    "\n",
    "  def build_model(self, n_inputs, n_outputs):\n",
    "    inputs = tf.keras.layers.Input(shape=(self.IM_SIZE, self.IM_SIZE, self.m))\n",
    "    x = tf.keras.layers.Conv2D(32, 8, (4, 4), activation='relu', padding='same', kernel_initializer='random_normal')(inputs)\n",
    "    x = tf.keras.layers.Conv2D(64, 4, (2, 2), activation='relu', padding='same', kernel_initializer='random_normal')(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 3, (1, 1), activation='relu', padding='same', kernel_initializer='random_normal')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, kernel_initializer='random_normal')(x)\n",
    "    outputs = tf.keras.layers.Dense(n_outputs, kernel_initializer='random_normal')(x)\n",
    "    model = tf.keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WAgXiNQ1TCUs"
   },
   "outputs": [],
   "source": [
    "win_trials = 100\n",
    "win_reward = { 'Breakout-v0' : 180.0 }\n",
    "scores = deque(maxlen=win_trials)\n",
    "\n",
    "episode_count = 3000\n",
    "state_size = env.observation_space.shape[0]\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "GGye7W9KU2bC",
    "outputId": "15a459bd-3ed7-498c-fc05-41d9e256cc1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 21, 21, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        32832     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3965440   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 4,045,476\n",
      "Trainable params: 4,045,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        32832     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               3965440   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 4,045,476\n",
      "Trainable params: 4,045,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(env.observation_space, env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDo6XIhMg4NN"
   },
   "outputs": [],
   "source": [
    "img = agent.preprocess_state(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "VX7R31sthB5e",
    "outputId": "8fdfdb62-0729-41f1-ee59-f833027b4321"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(11, 7))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Original observation (160×210 RGB)\")\n",
    "plt.imshow(obs)\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(122)\n",
    "plt.title(\"Preprocessed observation (84×84 greyscale)\")\n",
    "plt.imshow(tf.reshape(img, (84, 84)), interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "colab_type": "code",
    "id": "ZZLJO5Q5UwC-",
    "outputId": "acb2d671-1077-425d-aec5-c3658e001d92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_reinforce\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-2475a63fdd74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_reinforce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-9b9832268a0c>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0mq_values_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# update exploration-exploitation probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6738\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6739\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6740\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6741\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6742\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0;32m--> 960\u001b[0;31m                                                   stack(strides))\n\u001b[0m\u001b[1;32m    961\u001b[0m       if (packed_begin.dtype == dtypes.int64 or\n\u001b[1;32m    962\u001b[0m           \u001b[0mpacked_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                          as_ref=False):\n\u001b[1;32m    320\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in range(episode_count):\n",
    "  state = env.reset()\n",
    "  state = agent.preprocess_state(state)\n",
    "  state = agent.combine_images(state, state)\n",
    "  done = False\n",
    "  total_reward = 0\n",
    "  \n",
    "  while not done:\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    next_state = agent.preprocess_state(next_state)\n",
    "    next_state = agent.combine_images(next_state, state)\n",
    "    agent.remember(state, action, reward, next_state, done)\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "  \n",
    "  if len(agent.memory) >= batch_size:\n",
    "    print('batch_reinforce')\n",
    "    agent.replay(batch_size)\n",
    "  \n",
    "  scores.append(total_reward)\n",
    "  mean_score = np.mean(scores)\n",
    "\n",
    "  if mean_score >= win_reward['CartPole-v0'] and episode >= win_trials:\n",
    "    print(\"Solved in episode %d: Mean survival = %0.2lf in %d episodes\" % (episode, mean_score, win_trials))\n",
    "    agent.save_weights()\n",
    "    break\n",
    "  \n",
    "  if (episode + 1) % win_trials == 0:\n",
    "    print(\"Episode %d: Mean survival = %0.2lf in %d episodes\" % ((episode + 1), mean_score, win_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vODn0ICEjBiJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Viq7taCwg3U-"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rl.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
